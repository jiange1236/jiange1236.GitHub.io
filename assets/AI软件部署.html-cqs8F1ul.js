import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,a as i,o as n}from"./app-BdDoZcXW.js";const l={};function t(r,a){return n(),s("div",null,a[0]||(a[0]=[i(`<h1 id="ai软件部署" tabindex="-1"><a class="header-anchor" href="#ai软件部署"><span>AI软件部署</span></a></h1><h2 id="ollama" tabindex="-1"><a class="header-anchor" href="#ollama"><span>Ollama</span></a></h2><h3 id="自定义ollama安装路径" tabindex="-1"><a class="header-anchor" href="#自定义ollama安装路径"><span><a href="https://www.cnblogs.com/LaiYun/p/18696931" target="_blank" rel="noopener noreferrer">自定义Ollama安装路径</a></span></a></h3><p>由于Ollama的exe安装软件双击安装的时候默认是在C盘，以及后续的模型数据下载也在C盘，导致会占用C盘空间，所以这里单独写了一个自定义安装Ollama安装目录的教程。</p><p>Ollama官网地址：<a href="https://ollama.com" target="_blank" rel="noopener noreferrer">https://ollama.com</a></p><ul><li><strong>手动创建Ollama安装目录</strong></li></ul><p>首先在你想安装的路径下<strong>创建好一个新文件夹，并把Ollama的安装包放在里面</strong>。比如我的是：D:\\Ollama</p><p>在文件路径上输入CMD回车后会自动打开命令窗口</p><ul><li><strong>输入命令符安装</strong></li></ul><p>然后在CMD窗口输入：<code>OllamaSetup.exe /DIR=D:\\Ollama</code></p><p><strong>语法：软件名称 /DIR=这里放你上面创建好的Ollama指定目录</strong></p><p>然后Ollama就会进入安装，点击Install后，可以看到Ollama的安装路径就变成了我们指定的目录了，这样大模型数据包也会默认下载在指定目录中。 　　<strong>到这里Ollama自定义目录安装就完结了。</strong></p><p>最后再讲个特例，就是有些小伙伴的Ollama已经安装在C盘了，但是又不想重新安装Ollama，只想把大模型资源包不要默认下载到C盘。</p><ul><li><strong>手动创建大模型存储目录</strong></li></ul><p>首先先在你想要存储的盘符下创建好存储目录，比如我想存到E盘下面，我这里就创建了该目录：E:\\MySoftware\\Ollama</p><ul><li><strong>增加环境变量</strong></li></ul><p>然后鼠标右键我的电脑--&gt;属性--&gt;高级系统设置--&gt;环境变量</p><p>新建一个环境变量</p><p><strong>OLLAMA_MODELS</strong> ：<code>D:\\Ollama\\models</code></p><ul><li><strong>复制转移大模型存储目录</strong></li></ul><p>创建完环境变量后，把Ollama停止，然后进入C盘--&gt;用户--&gt;你自己的电脑名称--&gt;.ollama--&gt;复制整个models到刚刚上面新建的存储目录下。<strong>复制完成后要删除C盘目录下的models文件夹。</strong> 　　 　　复制到新创建的目录下</p><p><strong>重启电脑</strong>，打开CMD输入<strong>Ollama list</strong>，查看大模型资源包是否能正常显示，显示正常则迁移完成，也可以直接和大模型进行提问，能回复说明也正常。</p><h3 id="下载模型" tabindex="-1"><a class="header-anchor" href="#下载模型"><span>下载模型</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>ollama run modelscope.cn/unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="cherry-studio" tabindex="-1"><a class="header-anchor" href="#cherry-studio"><span>Cherry Studio</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>mklink /J &quot;C:\\Users\\JKYDesk\\AppData\\Roaming\\CherryStudio&quot; &quot;D:\\AppData\\CherryStudio&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="dify" tabindex="-1"><a class="header-anchor" href="#dify"><span>Dify</span></a></h2><p>env 文件</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>PIP_MIRROR_URL=https://pypi.tuna.tsinghua.edu.cn/simple/</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Dify的知识库默认上传文件大小限制为15M，对于我们要上传的文件有点小了，这里改为150M，可以根据实际情况做调整。</span></span>
<span class="line"><span># 上传文件大小改为150M</span></span>
<span class="line"><span>UPLOAD_FILE_SIZE_LIMIT=150</span></span>
<span class="line"><span># 上传图片大小改为150M</span></span>
<span class="line"><span>UPLOAD_IMAGE_FILE_SIZE_LIMIT=150</span></span>
<span class="line"><span># 上传视频大小改为1000M</span></span>
<span class="line"><span>UPLOAD_VIDEO_FILE_SIZE_LIMIT=1000</span></span>
<span class="line"><span># 上传音频大小改为500M</span></span>
<span class="line"><span>UPLOAD_AUDIO_FILE_SIZE_LIMIT=500</span></span>
<span class="line"><span>#NGINX上传限制改为150M，跟上面有没有冲突没有试，大概率是有的</span></span>
<span class="line"><span>NGINX_CLIENT_MAX_BODY_SIZE=150M</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>依赖安装</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>sudo apt install python3-pip build-essential libssl-dev libffi-dev python3-dev pipx libopenblas-dev liblapack-dev</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>安装 UV</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>pipx install --pip-args=&quot;-i https://pypi.tuna.tsinghua.edu.cn/simple&quot; uv</span></span>
<span class="line"><span>pipx ensurepath</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="dify-chat" tabindex="-1"><a class="header-anchor" href="#dify-chat"><span>Dify Chat</span></a></h3><p>修改 Dockerfile</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>RUN sed -i &#39;s@deb.debian.org@mirrors.aliyun.com@g&#39; /etc/apt/sources.list.d/debian.sources</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>docker build . -t difyv1/dify-chat</span></span>
<span class="line"><span>docker run -itd -p 3000:80 --name dify-chat --env-file ./docker/.env difyv1/dify-chat</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="mineru" tabindex="-1"><a class="header-anchor" href="#mineru"><span>MinerU</span></a></h2><p>安装</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>git clone https://github.com/opendatalab/MinerU.git</span></span>
<span class="line"><span>cd MinerU</span></span>
<span class="line"><span>uv venv</span></span>
<span class="line"><span>uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu</span></span>
<span class="line"><span>uv pip install -e .[core] -i https://mirrors.aliyun.com/pypi/simple</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>source .venv/bin/activate</span></span>
<span class="line"><span>mineru -p /root/MinerU.pdf -o /root/ -d cpu --source modelscope</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="comfyui" tabindex="-1"><a class="header-anchor" href="#comfyui"><span>ComfyUI</span></a></h2><h3 id="flux-1-kontext-dev" tabindex="-1"><a class="header-anchor" href="#flux-1-kontext-dev"><span>Flux. 1 Kontext Dev</span></a></h3><p>模型保存位置</p>`,45)]))}const o=e(l,[["render",t]]),c=JSON.parse('{"path":"/tech/AI/AI%E8%BD%AF%E4%BB%B6/AI%E8%BD%AF%E4%BB%B6%E9%83%A8%E7%BD%B2.html","title":"AI软件部署","lang":"zh-CN","frontmatter":{"title":"AI软件部署","date":"2025-07-21T00:00:00.000Z","category":["AI"],"tags":["AI","Ollama","Dify","MinerU","ComfyUI"],"article":true,"description":"AI软件部署 Ollama 自定义Ollama安装路径 由于Ollama的exe安装软件双击安装的时候默认是在C盘，以及后续的模型数据下载也在C盘，导致会占用C盘空间，所以这里单独写了一个自定义安装Ollama安装目录的教程。 Ollama官网地址：https://ollama.com 手动创建Ollama安装目录 首先在你想安装的路径下创建好一个新文...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI软件部署\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-07-21T00:00:00.000Z\\",\\"dateModified\\":\\"2025-07-21T01:29:50.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Zine⁶\\",\\"url\\":\\"https://zecdn.top\\"}]}"],["meta",{"property":"og:url","content":"https://jiange1236.github.io/tech/AI/AI%E8%BD%AF%E4%BB%B6/AI%E8%BD%AF%E4%BB%B6%E9%83%A8%E7%BD%B2.html"}],["meta",{"property":"og:site_name","content":"Zeblog"}],["meta",{"property":"og:title","content":"AI软件部署"}],["meta",{"property":"og:description","content":"AI软件部署 Ollama 自定义Ollama安装路径 由于Ollama的exe安装软件双击安装的时候默认是在C盘，以及后续的模型数据下载也在C盘，导致会占用C盘空间，所以这里单独写了一个自定义安装Ollama安装目录的教程。 Ollama官网地址：https://ollama.com 手动创建Ollama安装目录 首先在你想安装的路径下创建好一个新文..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-07-21T01:29:50.000Z"}],["meta",{"property":"article:tag","content":"ComfyUI"}],["meta",{"property":"article:tag","content":"MinerU"}],["meta",{"property":"article:tag","content":"Dify"}],["meta",{"property":"article:tag","content":"Ollama"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:published_time","content":"2025-07-21T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-07-21T01:29:50.000Z"}],["link",{"rel":"alternate","type":"application/atom+xml","href":"https://jiange1236.github.io/atom.xml","title":"Zeblog Atom Feed"}],["link",{"rel":"alternate","type":"application/json","href":"https://jiange1236.github.io/feed.json","title":"Zeblog JSON Feed"}],["link",{"rel":"alternate","type":"application/rss+xml","href":"https://jiange1236.github.io/rss.xml","title":"Zeblog RSS Feed"}]]},"git":{"createdTime":1742128842000,"updatedTime":1753061390000,"contributors":[{"name":"jiange1236","username":"jiange1236","email":"1384621+jiange1236@users.noreply.github.com","commits":3,"url":"https://github.com/jiange1236"}]},"readingTime":{"minutes":2.83,"words":848},"filePathRelative":"tech/AI/AI软件/AI软件部署.md","excerpt":"","autoDesc":true}');export{o as comp,c as data};
