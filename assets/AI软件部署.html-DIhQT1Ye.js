import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{e as t,f as l,o as i}from"./app-DuyuJ6on.js";const o={};function r(s,e){return i(),t("div",null,e[0]||(e[0]=[l('<h2 id="ollama" tabindex="-1"><a class="header-anchor" href="#ollama"><span>Ollama</span></a></h2><h3 id="自定义ollama安装路径" tabindex="-1"><a class="header-anchor" href="#自定义ollama安装路径"><span><a href="https://www.cnblogs.com/LaiYun/p/18696931" title="发布于 2025-02-02 17:33" target="_blank" rel="noopener noreferrer">自定义Ollama安装路径</a></span></a></h3><p>由于Ollama的exe安装软件双击安装的时候默认是在C盘，以及后续的模型数据下载也在C盘，导致会占用C盘空间，所以这里单独写了一个自定义安装Ollama安装目录的教程。</p><p>Ollama官网地址：<a href="https://ollama.com" target="_blank" rel="noopener noreferrer">https://ollama.com</a></p><ul><li><strong>手动创建Ollama安装目录</strong></li></ul><p>首先在你想安装的路径下<strong>创建好一个新文件夹，并把Ollama的安装包放在里面</strong>。比如我的是：D:\\Ollama</p><p>在文件路径上输入CMD回车后会自动打开命令窗口</p><ul><li><strong>输入命令符安装</strong></li></ul><p>然后在CMD窗口输入：<code>OllamaSetup.exe /DIR=D:\\Ollama</code></p><p><strong>语法：软件名称 /DIR=这里放你上面创建好的Ollama指定目录</strong></p><p>然后Ollama就会进入安装，点击Install后，可以看到Ollama的安装路径就变成了我们指定的目录了，这样大模型数据包也会默认下载在指定目录中。 　　<strong>到这里Ollama自定义目录安装就完结了。</strong></p><p>最后再讲个特例，就是有些小伙伴的Ollama已经安装在C盘了，但是又不想重新安装Ollama，只想把大模型资源包不要默认下载到C盘。</p><ul><li><strong>手动创建大模型存储目录</strong></li></ul><p>首先先在你想要存储的盘符下创建好存储目录，比如我想存到E盘下面，我这里就创建了该目录：E:\\MySoftware\\Ollama</p><ul><li><strong>增加环境变量</strong></li></ul><p>然后鼠标右键我的电脑--&gt;属性--&gt;高级系统设置--&gt;环境变量</p><p>新建一个环境变量</p><p><strong>OLLAMA_MODELS</strong> ：<code>D:\\Ollama\\models</code></p><ul><li><strong>复制转移大模型存储目录</strong></li></ul><p>创建完环境变量后，把Ollama停止，然后进入C盘--&gt;用户--&gt;你自己的电脑名称--&gt;.ollama--&gt;复制整个models到刚刚上面新建的存储目录下。<strong>复制完成后要删除C盘目录下的models文件夹。</strong> 　　 　　复制到新创建的目录下</p><p><strong>重启电脑</strong>，打开CMD输入<strong>Ollama list</strong>，查看大模型资源包是否能正常显示，显示正常则迁移完成，也可以直接和大模型进行提问，能回复说明也正常。</p><h3 id="下载模型" tabindex="-1"><a class="header-anchor" href="#下载模型"><span>下载模型</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>ollama run modelscope.cn/unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="cherry-studio" tabindex="-1"><a class="header-anchor" href="#cherry-studio"><span>Cherry Studio</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>mklink /J &quot;C:\\Users\\JKYDesk\\AppData\\Roaming\\CherryStudio&quot; &quot;D:\\AppData\\CherryStudio&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div>',25)]))}const m=a(o,[["render",r],["__file","AI软件部署.html.vue"]]),d=JSON.parse('{"path":"/study/AI/AI%E8%BD%AF%E4%BB%B6%E9%83%A8%E7%BD%B2.html","title":"","lang":"zh-CN","frontmatter":{"date":"2025-03-16T00:00:00.000Z","description":"Ollama 自定义Ollama安装路径 由于Ollama的exe安装软件双击安装的时候默认是在C盘，以及后续的模型数据下载也在C盘，导致会占用C盘空间，所以这里单独写了一个自定义安装Ollama安装目录的教程。 Ollama官网地址：https://ollama.com 手动创建Ollama安装目录 首先在你想安装的路径下创建好一个新文件夹，并把Ol...","head":[["meta",{"property":"og:url","content":"https://jiange1236.github.io/study/AI/AI%E8%BD%AF%E4%BB%B6%E9%83%A8%E7%BD%B2.html"}],["meta",{"property":"og:site_name","content":"Zeblog"}],["meta",{"property":"og:description","content":"Ollama 自定义Ollama安装路径 由于Ollama的exe安装软件双击安装的时候默认是在C盘，以及后续的模型数据下载也在C盘，导致会占用C盘空间，所以这里单独写了一个自定义安装Ollama安装目录的教程。 Ollama官网地址：https://ollama.com 手动创建Ollama安装目录 首先在你想安装的路径下创建好一个新文件夹，并把Ol..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-16T13:10:33.000Z"}],["meta",{"property":"article:published_time","content":"2025-03-16T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-16T13:10:33.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-03-16T00:00:00.000Z\\",\\"dateModified\\":\\"2025-03-16T13:10:33.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Zine⁶\\",\\"url\\":\\"https://zecdn.top\\"}]}"],["link",{"rel":"alternate","type":"application/atom+xml","href":"https://jiange1236.github.io/atom.xml","title":"Zeblog Atom Feed"}],["link",{"rel":"alternate","type":"application/json","href":"https://jiange1236.github.io/feed.json","title":"Zeblog JSON Feed"}],["link",{"rel":"alternate","type":"application/rss+xml","href":"https://jiange1236.github.io/rss.xml","title":"Zeblog RSS Feed"}]]},"git":{"createdTime":1742128842000,"updatedTime":1742130633000,"contributors":[{"name":"周子健","username":"周子健","email":"1384621+jiange1236@users.noreply.github.com","commits":2,"url":"https://github.com/周子健"}]},"readingTime":{"minutes":1.97,"words":591},"filePathRelative":"study/AI/AI软件部署.md","localizedDate":"2025年3月16日","excerpt":"","autoDesc":true}');export{m as comp,d as data};
